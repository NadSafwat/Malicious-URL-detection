{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import requests\n",
    "import socket\n",
    "import pickle\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import tldextract\n",
    "import pycountry\n",
    "from bs4 import BeautifulSoup\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "import mysql.connector\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [12/May/2024 15:37:18] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/May/2024 15:37:35] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://short.io is predicted [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [12/May/2024 15:37:43] \"OPTIONS /save_url HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/May/2024 15:37:57] \"POST /save_url HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/May/2024 15:38:00] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/May/2024 15:38:16] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://github.com is predicted [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [12/May/2024 15:38:36] \"OPTIONS /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.google.com is predicted [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [12/May/2024 15:38:50] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/May/2024 15:39:23] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/May/2024 15:40:03] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.haverford.edu/athletics/fieldhockey/ is predicted [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [12/May/2024 15:40:12] \"OPTIONS /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.cnn.com is predicted [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [12/May/2024 15:41:19] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/May/2024 15:41:21] \"OPTIONS /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.aucegypt.edu is predicted [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [12/May/2024 15:41:41] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/May/2024 15:42:05] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/May/2024 15:42:22] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://viatalia.com is predicted [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [12/May/2024 15:42:34] \"OPTIONS /save_url HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/May/2024 15:42:49] \"POST /save_url HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/May/2024 15:42:54] \"OPTIONS /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.bucklin.org/ is predicted [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [12/May/2024 15:43:31] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/May/2024 15:43:55] \"OPTIONS /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://viatalia.com is predicted 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [12/May/2024 15:44:14] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "connection = mysql.connector.connect(\n",
    "    host = \"localhost\", \n",
    "    user = \"root\", \n",
    "    password = \"Nad.Safwat123\", \n",
    "    database = \"ml\"\n",
    ")\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app) \n",
    "CORS(app, origins=[\"http://127.0.0.1:5500\"])\n",
    "\n",
    "with open(r\"..\\PickleFiles\\trained_ohe.pkl\", \"rb\") as ohe_file:\n",
    "    trained_ohe = pickle.load(ohe_file)\n",
    "\n",
    "def count_digits_in_string(s):\n",
    "    return sum(c.isdigit() for c in s)\n",
    "\n",
    "def compute_entropy(url):\n",
    "    char_count = len(url)\n",
    "    char_freq = {char: url.count(char) / char_count for char in set(url)}\n",
    "    entropy = -sum(p * math.log2(p) for p in char_freq.values())\n",
    "\n",
    "    # Normalize the entropy to [0, 1]\n",
    "    normalized_entropy = entropy / math.log2(char_count)\n",
    "\n",
    "    return round(normalized_entropy, 5)\n",
    "\n",
    "def transformIP(ip_add):\n",
    "    if ip_add == 0 or ip_add == '0':\n",
    "        return 0\n",
    "    else:\n",
    "        parts = ip_add.split('.')\n",
    "        return (int(parts[0]) << 24) + (int(parts[1]) << 16) + (int(parts[2]) << 8) + int(parts[3])\n",
    "\n",
    "def get_ip_address(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        hostname = urllib.parse.urlparse(response.url).hostname\n",
    "        ip_address = socket.gethostbyname(hostname)\n",
    "\n",
    "        return ip_address\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def get_js_len(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        script_tags = soup.find_all(\"script\")\n",
    "\n",
    "        total_length = sum(len(tag.text) for tag in script_tags)\n",
    "        return total_length\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def get_geo_loc(url):\n",
    "    try: \n",
    "        response = requests.get(url)\n",
    "        hostname = urllib.parse.urlparse(response.url).hostname\n",
    "        ip_address = socket.gethostbyname(hostname)\n",
    "\n",
    "        # Get geolocation data using IPinfo API (replace with your API key)\n",
    "        api_key = '89e9d2d437b634'\n",
    "        url = f\"https://ipinfo.io/{ip_address}/json?token={api_key}\"\n",
    "        response = requests.get(url)\n",
    "        geolocation_data = response.json()\n",
    "        try:\n",
    "            country = pycountry.countries.get(alpha_2=geolocation_data['country'])\n",
    "            return country.name\n",
    "        except:\n",
    "            return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def get_tld(url):\n",
    "    try:\n",
    "        tld_ext = tldextract.extract(url)\n",
    "        return tld_ext.suffix\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def process_data(url):\n",
    "    UserInput = {\n",
    "        'url_numOf_digits': count_digits_in_string(url),\n",
    "        'url_entropy': compute_entropy(url),\n",
    "        'url_len': len(url),\n",
    "        'ip_add': transformIP(get_ip_address(url)),\n",
    "        'who_is': 0,\n",
    "        'https': 1 if url.startswith('https') else 0,\n",
    "        'js_len': get_js_len(url),\n",
    "        'geo_loc': get_geo_loc(url),\n",
    "        'tld': get_tld(url)\n",
    "    }\n",
    "\n",
    "    return UserInput\n",
    "\n",
    "def ohe_data(UserInput):\n",
    "    InptData = pd.DataFrame([UserInput])\n",
    "    \n",
    "    ohetransform = trained_ohe.transform(InptData[['geo_loc', 'tld']]).astype('int8')\n",
    "    InptData = pd.concat([InptData,ohetransform], axis=1).drop(columns=['geo_loc', 'tld'])\n",
    "    return InptData\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    with open(r'..\\PickleFiles\\Model.pkl', 'rb') as m:\n",
    "        model = pickle.load(m)\n",
    "\n",
    "    cursor = connection.cursor(buffered=True)\n",
    "    cursor.execute(\"SELECT * FROM data_to_view\")\n",
    "    rows = cursor.fetchall()\n",
    "\n",
    "    url = request.get_json()\n",
    "    url = url['url']\n",
    "\n",
    "    urlExists = \"\"\"SELECT url FROM data_to_view WHERE url = '%s'\"\"\" % (url)\n",
    "    cursor.execute(urlExists)\n",
    "    if (cursor.fetchall() != []):\n",
    "        predict = \"\"\"SELECT label FROM data_to_view WHERE url = '%s'\"\"\" % (url)\n",
    "        cursor.execute(predict)\n",
    "        prediction = cursor.fetchall()[0][0]\n",
    "        print(f'{url} is predicted {prediction}')\n",
    "        cursor.close()\n",
    "        return jsonify([prediction])\n",
    "    else:\n",
    "        data = process_data(url)\n",
    "        data = ohe_data(data)\n",
    "        prediction = model.predict(data)\n",
    "        print(f'{url} is predicted {prediction}')\n",
    "        return jsonify(prediction.tolist())\n",
    "\n",
    "@app.route('/save_url', methods=['POST'])\n",
    "def save_url():\n",
    "    cursor = connection.cursor(buffered=True)\n",
    "    cursor.execute(\"SELECT * FROM data_to_view\")\n",
    "    rows = cursor.fetchall()\n",
    "\n",
    "    data = request.get_json()\n",
    "\n",
    "    url = data['url']\n",
    "    prediction = data['prediction']\n",
    "    feedback = data['isCorrect']\n",
    "\n",
    "    if feedback == 0:\n",
    "        if prediction == 1:\n",
    "            prediction = 0\n",
    "        else:\n",
    "            prediction = 1\n",
    "    \n",
    "    data = process_data(url)\n",
    "    addUser = \"\"\"INSERT INTO data_to_view VALUES ('%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s')\"\"\" % (\n",
    "        url, data['url_numOf_digits'], data['url_entropy'], data['url_len'], get_ip_address(url), data['geo_loc'], data['tld'], data['who_is'], data['https'], data['js_len'] , prediction)\n",
    "    cursor.execute(addUser)\n",
    "    connection.commit()\n",
    "    cursor.close()\n",
    "    return {'message': 'URL saved'}\n",
    "\n",
    "@app.after_request\n",
    "def add_cors_headers(response):\n",
    "    response.headers[\"Access-Control-Allow-Origin\"] = \"http://127.0.0.1:5500\"\n",
    "    response.headers[\"Access-Control-Allow-Methods\"] = \"POST\"\n",
    "    response.headers[\"Access-Control-Allow-Headers\"] = \"Content-Type\"\n",
    "    return response\n",
    "\n",
    "try:\n",
    "    if __name__ == '__main__':\n",
    "        app.run(port=5000, debug= False)\n",
    "except Exception as e:\n",
    "    print('Error:', e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
